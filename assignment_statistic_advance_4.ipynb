{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee717fb-b3df-4b5a-8f10-f212baf8f93d",
   "metadata": {},
   "source": [
    "# ASSIGNMENT STATISTIC ADVANCE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823b0f33-7d31-4a8c-84bf-941ab88bbfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_1_ANS :- Both t-tests and z-tests are statistical hypothesis tests used to determine whether the difference between two sample means is statistically significant or due to chance. However, the main difference between the two tests is the underlying assumptions made about the population distribution.\n",
      "\n",
      "A z-test assumes that the population variance is known, and the sample size is large enough (>30) for the Central Limit Theorem to apply. Therefore, it is typically used when the population variance is known, and the sample size is large enough to provide a representative sample of the population. For example, a z-test could be used to test whether the average height of basketball players in the NBA is significantly different from the average height of players in the WNBA, assuming that the population variance of height for each league is known.\n",
      "\n",
      "A t-test, on the other hand, assumes that the population variance is unknown and estimates it from the sample. It is typically used when the sample size is small (<30) and the population variance is unknown. For example, a t-test could be used to test whether there is a significant difference in the mean scores on a standardized test between two groups of students, such as those who received a specific educational intervention and those who did not.\n",
      "\n",
      "In summary, a z-test is used when the population variance is known and the sample size is large, while a t-test is used when the population variance is unknown and the sample size is small.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_1_ANS :- Both t-tests and z-tests are statistical hypothesis tests used to determine whether the difference between two sample means is statistically significant or due to chance. However, the main difference between the two tests is the underlying assumptions made about the population distribution.\\n\\nA z-test assumes that the population variance is known, and the sample size is large enough (>30) for the Central Limit Theorem to apply. Therefore, it is typically used when the population variance is known, and the sample size is large enough to provide a representative sample of the population. For example, a z-test could be used to test whether the average height of basketball players in the NBA is significantly different from the average height of players in the WNBA, assuming that the population variance of height for each league is known.\\n\\nA t-test, on the other hand, assumes that the population variance is unknown and estimates it from the sample. It is typically used when the sample size is small (<30) and the population variance is unknown. For example, a t-test could be used to test whether there is a significant difference in the mean scores on a standardized test between two groups of students, such as those who received a specific educational intervention and those who did not.\\n\\nIn summary, a z-test is used when the population variance is known and the sample size is large, while a t-test is used when the population variance is unknown and the sample size is small.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778ea4ad-e47f-47e5-b91a-38b0704e76ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_2_ANS :- In hypothesis testing, a one-tailed test is a statistical test in which the alternative hypothesis specifies the direction of the expected difference or relationship between two variables, while a two-tailed test is a statistical test in which the alternative hypothesis does not specify the direction of the expected difference or relationship.\n",
      "\n",
      "In a one-tailed test, the null hypothesis is rejected only if the observed data falls in one tail of the distribution, which represents the extreme end of the distribution based on the direction of the alternative hypothesis. For example, if we are testing the hypothesis that a new drug will increase the average score on a cognitive test, the one-tailed alternative hypothesis would state that the drug will increase the score. We would reject the null hypothesis only if the observed data shows a significant increase in the scores.\n",
      "\n",
      "In a two-tailed test, the null hypothesis is rejected if the observed data falls in either tail of the distribution, which represents the extreme ends of the distribution based on any direction. For example, if we are testing the hypothesis that there is a difference in the mean scores of two groups of students on a standardized test, the two-tailed alternative hypothesis would state that there is a significant difference between the two groups, without specifying whether the difference is positive or negative. We would reject the null hypothesis only if the observed data shows a significant difference between the two groups, regardless of the direction of the difference.\n",
      "\n",
      "In general, one-tailed tests are used when there is a clear directional prediction about the relationship or difference between two variables, while two-tailed tests are used when there is no clear directional prediction. It is important to specify the appropriate type of test before conducting a statistical analysis to ensure that the hypothesis is tested correctly.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_2_ANS :- In hypothesis testing, a one-tailed test is a statistical test in which the alternative hypothesis specifies the direction of the expected difference or relationship between two variables, while a two-tailed test is a statistical test in which the alternative hypothesis does not specify the direction of the expected difference or relationship.\\n\\nIn a one-tailed test, the null hypothesis is rejected only if the observed data falls in one tail of the distribution, which represents the extreme end of the distribution based on the direction of the alternative hypothesis. For example, if we are testing the hypothesis that a new drug will increase the average score on a cognitive test, the one-tailed alternative hypothesis would state that the drug will increase the score. We would reject the null hypothesis only if the observed data shows a significant increase in the scores.\\n\\nIn a two-tailed test, the null hypothesis is rejected if the observed data falls in either tail of the distribution, which represents the extreme ends of the distribution based on any direction. For example, if we are testing the hypothesis that there is a difference in the mean scores of two groups of students on a standardized test, the two-tailed alternative hypothesis would state that there is a significant difference between the two groups, without specifying whether the difference is positive or negative. We would reject the null hypothesis only if the observed data shows a significant difference between the two groups, regardless of the direction of the difference.\\n\\nIn general, one-tailed tests are used when there is a clear directional prediction about the relationship or difference between two variables, while two-tailed tests are used when there is no clear directional prediction. It is important to specify the appropriate type of test before conducting a statistical analysis to ensure that the hypothesis is tested correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a13573-20c7-4481-a533-65963d0b9a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_3_ANS :- In hypothesis testing, there are two types of errors that can occur: Type I errors and Type II errors.\n",
      "\n",
      "A Type I error occurs when the null hypothesis is rejected even though it is actually true. This means that the test incorrectly concludes that there is a significant difference or relationship between two variables, when in reality, there is no such difference or relationship. The probability of making a Type I error is denoted by the symbol alpha (α) and is typically set at 0.05 or 0.01.\n",
      "\n",
      "An example scenario of a Type I error is when a medical test for a rare disease produces a false positive result. If the null hypothesis is that the patient does not have the disease, but the test incorrectly indicates that they do, it would result in a Type I error.\n",
      "\n",
      "\n",
      "A Type II error, on the other hand, occurs when the null hypothesis is not rejected even though it is actually false. This means that the test fails to detect a significant difference or relationship between two variables, when in reality, there is such a difference or relationship. The probability of making a Type II error is denoted by the symbol beta (β).\n",
      "\n",
      "An example scenario of a Type II error is when a medical test for a disease produces a false negative result. If the null hypothesis is that the patient has the disease, but the test incorrectly indicates that they do not, it would result in a Type II error.\n",
      "\n",
      " In summary, Type I errors occur when a test incorrectly rejects the null hypothesis, while Type II errors occur when a test fails to reject the null hypothesis even though it is false. Both types of errors are important to consider in hypothesis testing as they can have serious consequences in different applications. The balance between the two types of errors depends on the specific context and application of the hypothesis test.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_3_ANS :- In hypothesis testing, there are two types of errors that can occur: Type I errors and Type II errors.\\n\\nA Type I error occurs when the null hypothesis is rejected even though it is actually true. This means that the test incorrectly concludes that there is a significant difference or relationship between two variables, when in reality, there is no such difference or relationship. The probability of making a Type I error is denoted by the symbol alpha (α) and is typically set at 0.05 or 0.01.\\n\\nAn example scenario of a Type I error is when a medical test for a rare disease produces a false positive result. If the null hypothesis is that the patient does not have the disease, but the test incorrectly indicates that they do, it would result in a Type I error.\\n\\n\\nA Type II error, on the other hand, occurs when the null hypothesis is not rejected even though it is actually false. This means that the test fails to detect a significant difference or relationship between two variables, when in reality, there is such a difference or relationship. The probability of making a Type II error is denoted by the symbol beta (β).\\n\\nAn example scenario of a Type II error is when a medical test for a disease produces a false negative result. If the null hypothesis is that the patient has the disease, but the test incorrectly indicates that they do not, it would result in a Type II error.\\n\\n In summary, Type I errors occur when a test incorrectly rejects the null hypothesis, while Type II errors occur when a test fails to reject the null hypothesis even though it is false. Both types of errors are important to consider in hypothesis testing as they can have serious consequences in different applications. The balance between the two types of errors depends on the specific context and application of the hypothesis test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f64e3df-b836-4c4f-b21e-c458f9814ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_4_ANS :- Bayesian statistic is an approch to data analysis and parameter estimation based on bayes theorem. and Bayes theorem / bayes statistic is used to solving problem in machine learning algorithm.\n",
      "\n",
      "Two type in Bayes Statistic Events\n",
      "\n",
      "1. Independent Event\n",
      "\n",
      "Example :- \n",
      "1. Rolling a dice\n",
      "{1,2,3,4,5,6}\n",
      "pr = 1/6 , 1/6 , ...\n",
      "\n",
      "2. Tossing a coin \n",
      "pr(H) = 0.5\n",
      "pr(T) = 0.5\n",
      "\n",
      "2. Dependent Event\n",
      "\n",
      "Example :-\n",
      "Five marble in bag ,two is black and three is white.\n",
      "pr(b) = 2/5\n",
      "pr(w) = 3/4\n",
      "\n",
      "pr(w and b) = pr(w)*pr(b/w)\n",
      "\n",
      "pr(A and B) = pr(B and A)\n",
      "\n",
      "pr(A)*pr(B/A) = pr(B)*pr(A/B)\n",
      "\n",
      "Formula :-\n",
      "\n",
      "pr(A/B) = pr(A)*pr(B/A)/pr(B)\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_4_ANS :- Bayesian statistic is an approch to data analysis and parameter estimation based on bayes theorem. and Bayes theorem / bayes statistic is used to solving problem in machine learning algorithm.\\n\\nTwo type in Bayes Statistic Events\\n\\n1. Independent Event\\n\\nExample :- \\n1. Rolling a dice\\n{1,2,3,4,5,6}\\npr = 1/6 , 1/6 , ...\\n\\n2. Tossing a coin \\npr(H) = 0.5\\npr(T) = 0.5\\n\\n2. Dependent Event\\n\\nExample :-\\nFive marble in bag ,two is black and three is white.\\npr(b) = 2/5\\npr(w) = 3/4\\n\\npr(w and b) = pr(w)*pr(b/w)\\n\\npr(A and B) = pr(B and A)\\n\\npr(A)*pr(B/A) = pr(B)*pr(A/B)\\n\\nFormula :-\\n\\npr(A/B) = pr(A)*pr(B/A)/pr(B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c287badd-7475-4dfe-b604-1ae4e3399b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_5_ANS :- Confidance Intirval :- ew construct the a confidance intirval to help estimate what the estimate value of the unknown population mean is \n",
      "\n",
      "point estimate +-margin of error\n",
      "\n",
      "Z-test = X! +- Zalpha/2 std/root(n)\n",
      "\n",
      "Example :- \n",
      " X! = 520\n",
      "std = 100\n",
      "n = 25\n",
      "C.I = 0.95\n",
      "alpha = 0.05\n",
      "\n",
      "Lower C.I = 520-(1.96)*100/root(25) = 480.8\n",
      "\n",
      "High C.I = 520+(1.96)*100/root(25) = 559.2\n",
      "\n",
      "Iam 95% confident that the mean less between 480.8 and 559.2.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_5_ANS :- Confidance Intirval :- ew construct the a confidance intirval to help estimate what the estimate value of the unknown population mean is \\n\\npoint estimate +-margin of error\\n\\nZ-test = X! +- Zalpha/2 std/root(n)\\n\\nExample :- \\n X! = 520\\nstd = 100\\nn = 25\\nC.I = 0.95\\nalpha = 0.05\\n\\nLower C.I = 520-(1.96)*100/root(25) = 480.8\\n\\nHigh C.I = 520+(1.96)*100/root(25) = 559.2\\n\\nIam 95% confident that the mean less between 480.8 and 559.2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27af8a6c-1701-4eff-8955-c5b6088cc4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_6_ANS :- Here's an example problem that demonstrates the use of Bayes' Theorem:\n",
      "\n",
      "Suppose a factory produces widgets that are either defective or non-defective. Historically, 10% of the widgets produced by the factory are defective. A quality control test is conducted on a randomly selected widget from the factory and the test has a false positive rate of 5%. If the quality control test indicates that the widget is defective, what is the probability that the widget is actually defective?\n",
      "\n",
      "Solution:\n",
      "\n",
      "Let's define the events as follows:\n",
      "\n",
      "Event A: the widget is defective\n",
      "\n",
      "Event B: the quality control test indicates that the widget is defective\n",
      "\n",
      "Using the information provided in the problem, we can determine the following probabilities:\n",
      "\n",
      "P(A) = 0.10 (prior probability of a widget being defective)\n",
      "\n",
      "P(B|A) = 1.0 (probability of the test indicating the widget is defective given that it is actually defective)\n",
      "\n",
      "P(B|not A) = 0.05 (false positive rate, i.e., probability of the test indicating the widget is defective given that it is not actually defective)\n",
      "\n",
      "We can now use Bayes' Theorem to calculate the probability that the widget is actually defective given that the quality control test indicates that it is defective:\n",
      "\n",
      "P(A|B) = P(B|A) * P(A) / P(B|A) * P(A) + P(B|not A) * P(not A)\n",
      "\n",
      "P(A|B) = 1.0 * 0.10 / (1.0 * 0.10 + 0.05 * 0.90)\n",
      "\n",
      "P(A|B) = 0.67\n",
      "\n",
      "Therefore, given that the quality control test indicates that the widget is defective, the probability that the widget is actually defective is 0.67 or 67%.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_6_ANS :- Here's an example problem that demonstrates the use of Bayes' Theorem:\\n\\nSuppose a factory produces widgets that are either defective or non-defective. Historically, 10% of the widgets produced by the factory are defective. A quality control test is conducted on a randomly selected widget from the factory and the test has a false positive rate of 5%. If the quality control test indicates that the widget is defective, what is the probability that the widget is actually defective?\\n\\nSolution:\\n\\nLet's define the events as follows:\\n\\nEvent A: the widget is defective\\n\\nEvent B: the quality control test indicates that the widget is defective\\n\\nUsing the information provided in the problem, we can determine the following probabilities:\\n\\nP(A) = 0.10 (prior probability of a widget being defective)\\n\\nP(B|A) = 1.0 (probability of the test indicating the widget is defective given that it is actually defective)\\n\\nP(B|not A) = 0.05 (false positive rate, i.e., probability of the test indicating the widget is defective given that it is not actually defective)\\n\\nWe can now use Bayes' Theorem to calculate the probability that the widget is actually defective given that the quality control test indicates that it is defective:\\n\\nP(A|B) = P(B|A) * P(A) / P(B|A) * P(A) + P(B|not A) * P(not A)\\n\\nP(A|B) = 1.0 * 0.10 / (1.0 * 0.10 + 0.05 * 0.90)\\n\\nP(A|B) = 0.67\\n\\nTherefore, given that the quality control test indicates that the widget is defective, the probability that the widget is actually defective is 0.67 or 67%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5be3dde-f5ea-4812-9330-049b81edc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_7_ANS :-To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we need to use the following formula:\n",
      "\n",
      "CI = X ± Z * (σ / sqrt(n))\n",
      "\n",
      "where:\n",
      "\n",
      "CI is the confidence interval\n",
      "X is the sample mean\n",
      "Z is the critical value from the standard normal distribution for the desired level of confidence (95% in this case)\n",
      "σ is the population standard deviation (unknown in this case, so we use the sample standard deviation as an estimate)\n",
      "n is the sample size\n",
      "\n",
      "To find the critical value Z for a 95% confidence level, we can look it up in a standard normal distribution table or use a calculator. The Z-value for a 95% confidence level is 1.96.\n",
      "\n",
      "Plugging in the values we have, we get:\n",
      "\n",
      "CI = 50 ± 1.96 * (5 / sqrt(n))\n",
      "\n",
      "We don't know the sample size (n) so we cannot calculate the exact confidence interval, but we can interpret the results based on this formula.\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "The 95% confidence interval represents a range of values that we can be 95% confident will contain the true population mean. In this case, the formula above tells us that the 95% confidence interval for the population mean based on the sample data with a mean of 50 and a standard deviation of 5 is given by the formula above. As we do not know the sample size, we cannot calculate the exact interval. However, assuming a large enough sample size, the interval would be relatively narrow, and we can say with 95% confidence that the true population mean lies within this interval. \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_7_ANS :-To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we need to use the following formula:\\n\\nCI = X ± Z * (σ / sqrt(n))\\n\\nwhere:\\n\\nCI is the confidence interval\\nX is the sample mean\\nZ is the critical value from the standard normal distribution for the desired level of confidence (95% in this case)\\nσ is the population standard deviation (unknown in this case, so we use the sample standard deviation as an estimate)\\nn is the sample size\\n\\nTo find the critical value Z for a 95% confidence level, we can look it up in a standard normal distribution table or use a calculator. The Z-value for a 95% confidence level is 1.96.\\n\\nPlugging in the values we have, we get:\\n\\nCI = 50 ± 1.96 * (5 / sqrt(n))\\n\\nWe don't know the sample size (n) so we cannot calculate the exact confidence interval, but we can interpret the results based on this formula.\\n\\nInterpretation:\\n\\nThe 95% confidence interval represents a range of values that we can be 95% confident will contain the true population mean. In this case, the formula above tells us that the 95% confidence interval for the population mean based on the sample data with a mean of 50 and a standard deviation of 5 is given by the formula above. As we do not know the sample size, we cannot calculate the exact interval. However, assuming a large enough sample size, the interval would be relatively narrow, and we can say with 95% confidence that the true population mean lies within this interval. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a845872-32be-4fb2-a572-74dfd35f3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_8_ANS :- The margin of error in a confidence interval is a measure of the uncertainty associated with our estimate of the population parameter (such as the population mean) based on a sample of data. It represents the amount by which our estimate could be expected to differ from the true population parameter, due to the randomness inherent in sampling.\n",
      "\n",
      "The margin of error is typically expressed as a range of values around the sample statistic (such as the sample mean or proportion), within which we can be confident the population parameter lies with a certain level of probability (such as 95% or 99%).\n",
      "\n",
      "The margin of error is affected by several factors, including the level of confidence desired, the variability of the population, and the sample size. Generally, a larger sample size will result in a smaller margin of error, as larger sample sizes provide more precise estimates of the population parameter. This is because larger samples provide more information about the population, and the variability in the sample statistic decreases as sample size increases.\n",
      "\n",
      "For example, suppose we want to estimate the average height of students in a particular school. If we take a sample of 50 students and calculate the sample mean, the margin of error at a 95% confidence level might be around ± 2.5 inches. However, if we increase the sample size to 500 students, the margin of error might decrease to around ± 0.8 inches, assuming everything else stays the same.\n",
      "\n",
      "In this scenario, a larger sample size would result in a smaller margin of error because a larger sample size would provide a more precise estimate of the population mean. The larger sample size would reduce the amount of variability in the sample statistic, allowing us to estimate the population parameter more accurately.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_8_ANS :- The margin of error in a confidence interval is a measure of the uncertainty associated with our estimate of the population parameter (such as the population mean) based on a sample of data. It represents the amount by which our estimate could be expected to differ from the true population parameter, due to the randomness inherent in sampling.\\n\\nThe margin of error is typically expressed as a range of values around the sample statistic (such as the sample mean or proportion), within which we can be confident the population parameter lies with a certain level of probability (such as 95% or 99%).\\n\\nThe margin of error is affected by several factors, including the level of confidence desired, the variability of the population, and the sample size. Generally, a larger sample size will result in a smaller margin of error, as larger sample sizes provide more precise estimates of the population parameter. This is because larger samples provide more information about the population, and the variability in the sample statistic decreases as sample size increases.\\n\\nFor example, suppose we want to estimate the average height of students in a particular school. If we take a sample of 50 students and calculate the sample mean, the margin of error at a 95% confidence level might be around ± 2.5 inches. However, if we increase the sample size to 500 students, the margin of error might decrease to around ± 0.8 inches, assuming everything else stays the same.\\n\\nIn this scenario, a larger sample size would result in a smaller margin of error because a larger sample size would provide a more precise estimate of the population mean. The larger sample size would reduce the amount of variability in the sample statistic, allowing us to estimate the population parameter more accurately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053e7692-695c-4cd7-9d74-54056f5b05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_9_ANS :- To calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5, we use the formula:\n",
      "\n",
      "z = (x - μ) / σ\n",
      "\n",
      "where:\n",
      "\n",
      "x is the data point value (75 in this case)\n",
      "μ is the population mean (70 in this case)\n",
      "σ is the population standard deviation (5 in this case)\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "z = (75 - 70) / 5 = 1\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "The calculated z-score of 1 indicates that the data point at 75 is one standard deviation above the population mean of 70. This means that the value of 75 is higher than the average value in the population by a moderate amount. The z-score allows us to standardize the data point and compare it to the rest of the population in a standardized unit of measure, which can be helpful in identifying outliers or extreme values in a data set.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_9_ANS :- To calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5, we use the formula:\\n\\nz = (x - μ) / σ\\n\\nwhere:\\n\\nx is the data point value (75 in this case)\\nμ is the population mean (70 in this case)\\nσ is the population standard deviation (5 in this case)\\n\\nPlugging in the values, we get:\\n\\nz = (75 - 70) / 5 = 1\\n\\nInterpretation:\\n\\nThe calculated z-score of 1 indicates that the data point at 75 is one standard deviation above the population mean of 70. This means that the value of 75 is higher than the average value in the population by a moderate amount. The z-score allows us to standardize the data point and compare it to the rest of the population in a standardized unit of measure, which can be helpful in identifying outliers or extreme values in a data set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4bbeae-d7c8-423c-8235-eac9dd0f98ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_10_ANS :-To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence level, we need to set up the null and alternative hypotheses and then perform a t-test.Null hypothesis: The weight loss drug is not significantly effective, and the population mean weight loss is equal to or less than 0 pounds.\n",
      "Alternative hypothesis: The weight loss drug is significantly effective, and the population mean weight loss is greater than 0 pounds.\n",
      "\n",
      "We will use a one-tailed t-test since the alternative hypothesis is directional (greater than 0 pounds).\n",
      "\n",
      "The test statistic for a one-sample t-test is:\n",
      "\n",
      "t = (x̄ - μ) / (s / √n)\n",
      "\n",
      "where:\n",
      "\n",
      "x̄ is the sample mean (6 pounds in this case)\n",
      "μ is the hypothesized population mean (0 pounds in this case)\n",
      "s is the sample standard deviation (2.5 pounds in this case)\n",
      "n is the sample size (50 in this case)\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "t = (6 - 0) / (2.5 / √50) = 15.81\n",
      "\n",
      "The degrees of freedom for this test is n - 1 = 49.\n",
      "\n",
      "Using a t-table or a statistical software, we can find the critical value for a one-tailed t-test with 49 degrees of freedom and a 95% confidence level, which is approximately 1.677.\n",
      "\n",
      "Since our calculated t-value of 15.81 is greater than the critical value of 1.677, we can reject the null hypothesis and conclude that the weight loss drug is significantly effective at a 95% confidence level.\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "Based on the sample of 50 participants, the weight loss drug resulted in an average weight loss of 6 pounds, which was significantly greater than 0 pounds. Therefore, we can conclude that the weight loss drug is significantly effective at a 95% confidence level. \n"
     ]
    }
   ],
   "source": [
    "print(\"Q_10_ANS :-To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence level, we need to set up the null and alternative hypotheses and then perform a t-test.Null hypothesis: The weight loss drug is not significantly effective, and the population mean weight loss is equal to or less than 0 pounds.\\nAlternative hypothesis: The weight loss drug is significantly effective, and the population mean weight loss is greater than 0 pounds.\\n\\nWe will use a one-tailed t-test since the alternative hypothesis is directional (greater than 0 pounds).\\n\\nThe test statistic for a one-sample t-test is:\\n\\nt = (x̄ - μ) / (s / √n)\\n\\nwhere:\\n\\nx̄ is the sample mean (6 pounds in this case)\\nμ is the hypothesized population mean (0 pounds in this case)\\ns is the sample standard deviation (2.5 pounds in this case)\\nn is the sample size (50 in this case)\\n\\nPlugging in the values, we get:\\n\\nt = (6 - 0) / (2.5 / √50) = 15.81\\n\\nThe degrees of freedom for this test is n - 1 = 49.\\n\\nUsing a t-table or a statistical software, we can find the critical value for a one-tailed t-test with 49 degrees of freedom and a 95% confidence level, which is approximately 1.677.\\n\\nSince our calculated t-value of 15.81 is greater than the critical value of 1.677, we can reject the null hypothesis and conclude that the weight loss drug is significantly effective at a 95% confidence level.\\n\\nInterpretation:\\n\\nBased on the sample of 50 participants, the weight loss drug resulted in an average weight loss of 6 pounds, which was significantly greater than 0 pounds. Therefore, we can conclude that the weight loss drug is significantly effective at a 95% confidence level. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b4e7230-a819-433d-9653-2254e1c1b13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_11_ANS :- To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\n",
      "\n",
      "CI = p ± z*(sqrt(p*(1-p)/n))\n",
      "\n",
      "where:\n",
      "\n",
      "p is the sample proportion (0.65 in this case)\n",
      "n is the sample size (500 in this case)\n",
      "z is the critical value of the standard normal distribution corresponding to the desired confidence level (1.96 for a 95% confidence level)\n",
      "Plugging in the values, we get:\n",
      "\n",
      "CI = 0.65 ± 1.96*(sqrt(0.65*(1-0.65)/500))\n",
      "\n",
      "Simplifying the expression, we get:\n",
      "\n",
      "CI = 0.65 ± 0.045\n",
      "\n",
      "Therefore, the 95% confidence interval for the true proportion of people who are satisfied with their job is (0.605, 0.695).\n",
      "\n",
      "Interpretation:\n",
      "We can be 95% confident that the true proportion of people who are satisfied with their job falls between 0.605 and 0.695. This means that if we were to repeat the survey many times and calculate the confidence intervals for each survey, approximately 95% of the intervals would contain the true proportion of people who are satisfied with their job.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_11_ANS :- To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\\n\\nCI = p ± z*(sqrt(p*(1-p)/n))\\n\\nwhere:\\n\\np is the sample proportion (0.65 in this case)\\nn is the sample size (500 in this case)\\nz is the critical value of the standard normal distribution corresponding to the desired confidence level (1.96 for a 95% confidence level)\\nPlugging in the values, we get:\\n\\nCI = 0.65 ± 1.96*(sqrt(0.65*(1-0.65)/500))\\n\\nSimplifying the expression, we get:\\n\\nCI = 0.65 ± 0.045\\n\\nTherefore, the 95% confidence interval for the true proportion of people who are satisfied with their job is (0.605, 0.695).\\n\\nInterpretation:\\nWe can be 95% confident that the true proportion of people who are satisfied with their job falls between 0.605 and 0.695. This means that if we were to repeat the survey many times and calculate the confidence intervals for each survey, approximately 95% of the intervals would contain the true proportion of people who are satisfied with their job.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5874a1-4266-4ebb-b81f-0c27d54fb2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_12_ANS :- To conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance, we need to set up the null and alternative hypotheses and then perform a t-test.\n",
      "\n",
      "Null hypothesis: The two teaching methods have no significant difference in student performance, and the population means are equal.\n",
      "\n",
      "Alternative hypothesis: The two teaching methods have a significant difference in student performance, and the population means are not equal.\n",
      "\n",
      "We will use a two-sample t-test with unequal variances since the standard deviations of the two samples are different.\n",
      "\n",
      "The test statistic for a two-sample t-test with unequal variances is:\n",
      "\n",
      "t = (x̄1 - x̄2 - D) / sqrt((s1^2/n1) + (s2^2/n2))\n",
      "\n",
      "where:\n",
      "\n",
      "x̄1 and x̄2 are the sample means (85 and 82, respectively)\n",
      "s1 and s2 are the sample standard deviations (6 and 5, respectively)\n",
      "n1 and n2 are the sample sizes (assuming equal sample sizes, n1 = n2 = 30, for example)\n",
      "D is the hypothesized difference in population means under the null hypothesis (0 in this case)\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "t = (85 - 82 - 0) / sqrt((6^2/30) + (5^2/30)) = 2.68\n",
      "\n",
      "The degrees of freedom for this test is:\n",
      "\n",
      "df = ((s1^2/n1) + (s2^2/n2))^2 / ((s1^2/n1)^2 / (n1-1) + (s2^2/n2)^2 / (n2-1))\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "df = ((6^2/30) + (5^2/30))^2 / ((6^2/30)^2 / 29 + (5^2/30)^2 / 29) = 53.63 (rounded to 54)\n",
      "\n",
      "Using a t-table or a statistical software, we can find the critical value for a two-tailed t-test with 54 degrees of freedom and a significance level of 0.01, which is approximately ±2.681.\n",
      "\n",
      "Since our calculated t-value of 2.68 falls within the rejection region, we can reject the null hypothesis and conclude that the two teaching methods have a significant difference in student performance at a 99% confidence level.\n",
      "\n",
      "Interpretation:\n",
      "Based on the samples of student performance, there is evidence to suggest that the two teaching methods have different effects on student performance. The sample with the mean score of 85 has a significantly higher mean score than the sample with the mean score of 82.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_12_ANS :- To conduct a hypothesis test to determine if the two teaching methods have a significant difference in student performance, we need to set up the null and alternative hypotheses and then perform a t-test.\\n\\nNull hypothesis: The two teaching methods have no significant difference in student performance, and the population means are equal.\\n\\nAlternative hypothesis: The two teaching methods have a significant difference in student performance, and the population means are not equal.\\n\\nWe will use a two-sample t-test with unequal variances since the standard deviations of the two samples are different.\\n\\nThe test statistic for a two-sample t-test with unequal variances is:\\n\\nt = (x̄1 - x̄2 - D) / sqrt((s1^2/n1) + (s2^2/n2))\\n\\nwhere:\\n\\nx̄1 and x̄2 are the sample means (85 and 82, respectively)\\ns1 and s2 are the sample standard deviations (6 and 5, respectively)\\nn1 and n2 are the sample sizes (assuming equal sample sizes, n1 = n2 = 30, for example)\\nD is the hypothesized difference in population means under the null hypothesis (0 in this case)\\n\\nPlugging in the values, we get:\\n\\nt = (85 - 82 - 0) / sqrt((6^2/30) + (5^2/30)) = 2.68\\n\\nThe degrees of freedom for this test is:\\n\\ndf = ((s1^2/n1) + (s2^2/n2))^2 / ((s1^2/n1)^2 / (n1-1) + (s2^2/n2)^2 / (n2-1))\\n\\nPlugging in the values, we get:\\n\\ndf = ((6^2/30) + (5^2/30))^2 / ((6^2/30)^2 / 29 + (5^2/30)^2 / 29) = 53.63 (rounded to 54)\\n\\nUsing a t-table or a statistical software, we can find the critical value for a two-tailed t-test with 54 degrees of freedom and a significance level of 0.01, which is approximately ±2.681.\\n\\nSince our calculated t-value of 2.68 falls within the rejection region, we can reject the null hypothesis and conclude that the two teaching methods have a significant difference in student performance at a 99% confidence level.\\n\\nInterpretation:\\nBased on the samples of student performance, there is evidence to suggest that the two teaching methods have different effects on student performance. The sample with the mean score of 85 has a significantly higher mean score than the sample with the mean score of 82.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec601eb9-3a13-45e9-9b7d-40475529ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_13_ANS :- To calculate the 90% confidence interval for the true population mean, we need to use the following formula:\n",
      "\n",
      "CI = x̄ ± z*(σ/√n)\n",
      "\n",
      "where:\n",
      "\n",
      "x̄ is the sample mean (65)\n",
      "σ is the population standard deviation (8)\n",
      "n is the sample size (50)\n",
      "z is the critical value of the standard normal distribution for a 90% confidence level (1.645)\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "CI = 65 ± 1.645*(8/√50)\n",
      "CI = 65 ± 2.324\n",
      "\n",
      "The confidence interval ranges from 62.68 to 67.32.\n",
      "\n",
      "Interpretation:\n",
      "We are 90% confident that the true population mean falls within the range of 62.68 to 67.32. This means that if we were to repeat the sampling process many times, we would expect the true population mean to be within this range in 90% of the samples.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_13_ANS :- To calculate the 90% confidence interval for the true population mean, we need to use the following formula:\\n\\nCI = x̄ ± z*(σ/√n)\\n\\nwhere:\\n\\nx̄ is the sample mean (65)\\nσ is the population standard deviation (8)\\nn is the sample size (50)\\nz is the critical value of the standard normal distribution for a 90% confidence level (1.645)\\n\\nPlugging in the values, we get:\\n\\nCI = 65 ± 1.645*(8/√50)\\nCI = 65 ± 2.324\\n\\nThe confidence interval ranges from 62.68 to 67.32.\\n\\nInterpretation:\\nWe are 90% confident that the true population mean falls within the range of 62.68 to 67.32. This means that if we were to repeat the sampling process many times, we would expect the true population mean to be within this range in 90% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f55d0f9-2dda-49f3-a36e-711efe18b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_14_ANS :- To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we will use the following steps:\n",
      "\n",
      "Step 1: State the null and alternative hypotheses.\n",
      "\n",
      "Null hypothesis: The average reaction time with caffeine is the same as the average reaction time without caffeine.\n",
      "Alternative hypothesis: The average reaction time with caffeine is different from the average reaction time without caffeine.\n",
      "\n",
      "H0: μc = μ0\n",
      "Ha: μc ≠ μ0\n",
      "\n",
      "where:\n",
      "μc = population mean reaction time with caffeine\n",
      "μ0 = population mean reaction time without caffeine\n",
      "\n",
      "Step 2: Set the level of significance (α) and determine the critical value.\n",
      "\n",
      "Since we want to conduct the test at a 90% confidence level, the level of significance (α) is 0.1 (1-0.9). The degrees of freedom for the t-test is (n-1) = 29. Using a t-table or calculator, the critical values for a two-tailed t-test at a 0.1 level of significance with 29 degrees of freedom is ±1.699.\n",
      "\n",
      "Step 3: Calculate the test statistic.\n",
      "\n",
      "The test statistic for a t-test is calculated using the formula:\n",
      "\n",
      "t = (x̄ - μ0) / (s / sqrt(n))\n",
      "\n",
      "where:\n",
      "x̄ = sample mean (0.25 seconds)\n",
      "μ0 = hypothesized population mean without caffeine\n",
      "s = sample standard deviation (0.05 seconds)\n",
      "n = sample size (30)\n",
      "\n",
      "Plugging in the values, we get:\n",
      "\n",
      "t = (0.25 - μ0) / (0.05 / sqrt(30))\n",
      "\n",
      "Step 4: Determine the p-value.\n",
      "\n",
      "Using a t-table or calculator with 29 degrees of freedom, we find that the p-value for the calculated t-value is less than 0.1.\n",
      "\n",
      "Step 5: Make a decision and interpret the results.\n",
      "\n",
      "Since the p-value (less than 0.1) is less than the level of significance (0.1), we reject the null hypothesis. This means that there is evidence to suggest that the average reaction time with caffeine is different from the average reaction time without caffeine at a 90% confidence level.\n",
      "\n",
      "Interpretation:\n",
      "Based on the sample of 30 participants, we found that caffeine has a significant effect on reaction time. However, we cannot say with certainty whether this effect is positive or negative, only that there is a difference in reaction times between those who consume caffeine and those who do not. Further research may be needed to determine the direction and magnitude of this effect.\n"
     ]
    }
   ],
   "source": [
    "print(\"Q_14_ANS :- To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we will use the following steps:\\n\\nStep 1: State the null and alternative hypotheses.\\n\\nNull hypothesis: The average reaction time with caffeine is the same as the average reaction time without caffeine.\\nAlternative hypothesis: The average reaction time with caffeine is different from the average reaction time without caffeine.\\n\\nH0: μc = μ0\\nHa: μc ≠ μ0\\n\\nwhere:\\nμc = population mean reaction time with caffeine\\nμ0 = population mean reaction time without caffeine\\n\\nStep 2: Set the level of significance (α) and determine the critical value.\\n\\nSince we want to conduct the test at a 90% confidence level, the level of significance (α) is 0.1 (1-0.9). The degrees of freedom for the t-test is (n-1) = 29. Using a t-table or calculator, the critical values for a two-tailed t-test at a 0.1 level of significance with 29 degrees of freedom is ±1.699.\\n\\nStep 3: Calculate the test statistic.\\n\\nThe test statistic for a t-test is calculated using the formula:\\n\\nt = (x̄ - μ0) / (s / sqrt(n))\\n\\nwhere:\\nx̄ = sample mean (0.25 seconds)\\nμ0 = hypothesized population mean without caffeine\\ns = sample standard deviation (0.05 seconds)\\nn = sample size (30)\\n\\nPlugging in the values, we get:\\n\\nt = (0.25 - μ0) / (0.05 / sqrt(30))\\n\\nStep 4: Determine the p-value.\\n\\nUsing a t-table or calculator with 29 degrees of freedom, we find that the p-value for the calculated t-value is less than 0.1.\\n\\nStep 5: Make a decision and interpret the results.\\n\\nSince the p-value (less than 0.1) is less than the level of significance (0.1), we reject the null hypothesis. This means that there is evidence to suggest that the average reaction time with caffeine is different from the average reaction time without caffeine at a 90% confidence level.\\n\\nInterpretation:\\nBased on the sample of 30 participants, we found that caffeine has a significant effect on reaction time. However, we cannot say with certainty whether this effect is positive or negative, only that there is a difference in reaction times between those who consume caffeine and those who do not. Further research may be needed to determine the direction and magnitude of this effect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e328cd-cd51-4509-b853-f59eef396ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
